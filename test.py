import argparse
import evaluate_MemNet
import torch


def parse_config():
    parser = argparse.ArgumentParser()
    parser.add_argument("--cuda", default=True)
    parser.add_argument("--batch_size", type=int, default=64)
    parser.add_argument("--past_len", type=int, default=20)
    parser.add_argument("--future_len", type=int, default=40)
    parser.add_argument("--dim_embedding_key", type=int, default=48)

    parser.add_argument("--model_classic_flag", type=bool, default=False)
    parser.add_argument("--preds", type=int, default=5)  #1,5,20  -> load a different pretrained model in MANTRA+ESA setting

    #'pretrained_models/mantra_tran/model_new'
    #CLASSIC
    parser.add_argument("--model", default='pretrained_models/MANTRA/model_mantra_10')

    parser.add_argument("--visualize_dataset", default=False)
    parser.add_argument("--saved_memory", default=True)
    parser.add_argument("--memories_path", default='pretrained_models/MANTRA/memories/')
    parser.add_argument("--withIRM", default=True, help='generate predictions with/without IRM')
    parser.add_argument("--saveImages", default='Subset',
                        help=
                        '''
                        Save in test folder examples of dataset with predictions generated by MANTRA.
                        If None, it does not save anything.
                        If 'All', it saves all examples.
                        If 'Subset', it saves examples defined in index_qualitative.py (handpicked significant samples)
                        ''')

    parser.add_argument("--dataset_file", default="kitti_dataset.json", help="dataset file")
    parser.add_argument("--info", type=str, default='', help='Name of evaluation. '
                                                             'It will use for name of the test folder.')
    return parser.parse_args()


def main(config):
    v = evaluate_MemNet.Validator(config)
    print('start evaluation')
    v.test_model()


if __name__ == "__main__":
    config = parse_config()
    print(torch.cuda.is_available())
    print(torch.__version__)
    main(config)














    #parser.add_argument("--model", default='training/training_tran/2022-06-14 12:20:37_mantra++_memoryTrue/model_IRM_epoch_249_2022-06-14 12:20:37')
    #parser.add_argument("--model", default='training/training_tran/2022-04-29 00:12:08_multihead_5_linear2/model_mantra_2022-04-29 00:12:08')
    #parser.add_argument("--model", default='training/training_tran/2022-04-29 16:59:04_multihead_5_linear2_continue/model_IRM_epoch_99_2022-04-29 16:59:04')
    #parser.add_argument("--model", default='pretrained_models/mantra_tran/model_new')
